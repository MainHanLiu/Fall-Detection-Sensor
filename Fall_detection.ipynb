{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998bfab8-5eb7-414d-bbe0-20645096d422",
   "metadata": {},
   "source": [
    "## sisfall_dataset으로 훈련시킨 LSTM 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1db34-6ebe-4818-87bf-78a07680d795",
   "metadata": {},
   "source": [
    "### 1. 종속성 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34f2599-e884-459f-80c5-a002b2b391c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파이썬 데이터과학, 기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e76297-d3a2-48f9-a239-4e73469c1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 머신러닝, 딥러닝 모델 라이브러리\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
    "from tensorflow.keras.losses import Huber, binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d352bd9-1742-49a0-b04a-c8864ba926de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm # 진행률 프로세스바"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a42aa41-7322-4576-8da5-1b104cd912f9",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b32def-8fd5-44f1-a5f4-b6dfd6881167",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',100) # pandas 표를 출력할 때 최대 행 수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7605c1c1-f85b-4dd2-9475-fb801d40549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 디렉터리 구조, 경로\n",
    "\n",
    "path = './SisFall_csv/'\n",
    "\n",
    "person = ['SA01','SA02','SA03','SA04','SA05','SA06','SA07','SA08','SA09','SA10','SA11','SA12','SA13','SA14','SA15','SA16','SA17','SA18','SA19','SA20', 'SA21','SA22','SA23',\n",
    "         'SE01', 'SE02', 'SE03', 'SE04', 'SE05', 'SE06', 'SE07', 'SE08', 'SE09', 'SE10', 'SE11', 'SE12', 'SE13', 'SE14', 'SE15']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0073948-3798-48fe-bb9f-ced02070dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailies = ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17', 'D18', 'D19']\n",
    "falls = ['F01', 'F02', 'F03', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15']\n",
    "\n",
    "trials = ['R01', 'R02','R03','R04','R05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb44df49-a9d4-4300-88f5-b43cd633a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 불러오기 함수\n",
    "\n",
    "def load_dataset(person):\n",
    "    subjectList = []\n",
    "    adl_list = []\n",
    "    fall_list = []\n",
    "    for man in person:\n",
    "        a = pd.read_csv(path + f'{man}.csv')\n",
    "        df = a[['ADXL_x', 'ADXL_y', 'ADXL_z', 'ITG_x', 'ITG_y', 'ITG_z', 'subject', 'activity', 'trial']]\n",
    "        subjectList.append(df)\n",
    "    \n",
    "    # 데이터를 ADLs과 Falls로 나누기\n",
    "    for s in subjectList:\n",
    "        for d in dailies:\n",
    "            tempdf = s[s['activity'] == d]\n",
    "            adl_list.append(tempdf)\n",
    "\n",
    "        for f in falls:\n",
    "            tempdf = s[s['activity'] == f]\n",
    "            fall_list.append(tempdf)\n",
    "            \n",
    "    return fall_list, adl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a02ccfc-5383-464a-94ac-4829b6bce1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트용으로 시각화 출력해주는 함수\n",
    "\n",
    "def printer(df, min_max=True, range=[0,3000], *args):\n",
    "    idx = {}\n",
    "    if min_max:\n",
    "        x = df.drop(['activity','person'],axis=1).astype('float64')\n",
    "        k = (x - x.min()) / (x.max() - x.min())\n",
    "        for w in args:\n",
    "            plt.plot(k[w],label=w)\n",
    "            idx[w] = df[w][df[w] == df[w].max()].index.values\n",
    "        plt.title(f'person:{df.person[0]}  ,  activity:{df.activity[0]}')\n",
    "        plt.xlim(range)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        for w in idx:\n",
    "            print(f'{w} : {idx[w]}')\n",
    "    else:\n",
    "        for w in args:\n",
    "            plt.plot(df[w],label=w)\n",
    "        plt.title(df.activity[0])\n",
    "        plt.xlim(range)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f3800-51b0-49c6-92a2-ebd0f0c81501",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8ffe74-1fde-4b6c-adad-ccfe6fcff308",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 필터링 함수\n",
    "order = 4 # 차수\n",
    "fs = 200 # 샘플주파수\n",
    "cutoff = 5.0 # 차단주파수\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419788a5-b8d6-43f5-b5fe-19f9dbe0ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 특성 추출 함수\n",
    "def feature_extraction(df):\n",
    "    df_list = []\n",
    "    rol_val = 200\n",
    "    for my_df in df:\n",
    "        for trial in trials:\n",
    "            trial_df = my_df[my_df['trial'] == trial]\n",
    "            if len(trial_df) == 0:\n",
    "                continue\n",
    "            trial_df.reset_index(inplace=True)\n",
    "            \n",
    "            tempdf = pd.DataFrame()\n",
    "            \n",
    "            # 데이터 필터링 : butterworth lowpass filtering ( fx = 필터링된 가속도센서 x축 )\n",
    "            # [특성1] vm2 : 필터링된 가속도센서 (x,y,z축)데이터들의 합, Sum vector magnitude\n",
    "            tempdf['ax'], tempdf['ay'], tempdf['az'] = trial_df['ADXL_x'], trial_df['ADXL_y'], trial_df['ADXL_z']\n",
    "            \n",
    "            tempdf['fx'] = pd.Series(butter_lowpass_filter(tempdf['ax'], cutoff, fs, order))\n",
    "            tempdf['fy'] = pd.Series(butter_lowpass_filter(tempdf['ay'], cutoff, fs, order))\n",
    "            tempdf['fz'] = pd.Series(butter_lowpass_filter(tempdf['az'], cutoff, fs, order))\n",
    "            tempdf['vm2'] =np.sqrt(tempdf['fx'] ** 2 + tempdf['fy'] ** 2 + tempdf['fz'] ** 2)\n",
    "\n",
    "            \n",
    "            # [특성2] diff_sum : 요소 간 차이의 합 ( bx = 필터링된 가속도센서 데이터에서 x축 요소들간의 차 )\n",
    "            tempdf['bx'] = tempdf['fx'].diff()\n",
    "            tempdf['by'] = tempdf['fy'].diff()\n",
    "            tempdf['bz'] = tempdf['fz'].diff()\n",
    "            tempdf['diff_sum'] = np.sqrt(tempdf['bx'] ** 2 + tempdf['by'] ** 2 + tempdf['bz'] ** 2)\n",
    "        \n",
    "            \n",
    "            # [특성3] g_sum : 필터링된 자이로센서 (x,y,z축)데이터들의 합\n",
    "            tempdf['gx'], tempdf['gy'], tempdf['gz'] = trial_df['ITG_x'], trial_df['ITG_y'], trial_df['ITG_z']\n",
    "            \n",
    "            tempdf['g_fx'] = pd.Series(butter_lowpass_filter(tempdf['gx'], cutoff, fs, order))\n",
    "            tempdf['g_fy'] = pd.Series(butter_lowpass_filter(tempdf['gy'], cutoff, fs, order))\n",
    "            tempdf['g_fz'] = pd.Series(butter_lowpass_filter(tempdf['gz'], cutoff, fs, order))\n",
    "            tempdf['g_sum'] = np.sqrt(tempdf['g_fx'] ** 2 + tempdf['g_fy'] ** 2 + tempdf['g_fz'] ** 2)\n",
    "\n",
    "\n",
    "            # [특성]\n",
    "            tempdf['activity'] = trial_df['activity']\n",
    "            tempdf['person'] = trial_df['subject']\n",
    "\n",
    "\n",
    "            ## ==================================================================\n",
    "            # 아래는 사용하지 않은 특성들 (sisfall논문에서 성능이 잘 나왔던 지표들의 특성들)\n",
    "            # 롤링 표준편차 Rolling standard deviations\n",
    "            tempdf['fx_std'] = tempdf['fx'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['fy_std'] = tempdf['fy'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['fz_std'] = tempdf['fz'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['bx_std'] = tempdf['bx'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['by_std'] = tempdf['by'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['bz_std'] = tempdf['bz'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['gx_std'] = tempdf['gx'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['gy_std'] = tempdf['gy'].rolling(rol_val,min_periods = 1).std()\n",
    "            tempdf['gz_std'] = tempdf['gz'].rolling(rol_val,min_periods = 1).std()\n",
    "\n",
    "            #C8\n",
    "            tempdf['horiz_std_mag9'] = np.sqrt(tempdf['fx_std'] ** 2 + tempdf['fz_std'] ** 2)\n",
    "            #C2\n",
    "            tempdf['horiz_vector_mag9'] = np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2)\n",
    "            tempdf['std_mag9'] = np.sqrt(tempdf['fx_std'] ** 2 + tempdf['fy_std'] ** 2 + tempdf['fz_std'] ** 2)\n",
    "            #C9\n",
    "            tempdf['horiz_std_mag2'] = np.sqrt(tempdf['bx_std'] ** 2 + tempdf['bz_std'] ** 2)\n",
    "            tempdf['gyro_horiz_std_mag'] = np.sqrt(tempdf['gx_std'] ** 2 + tempdf['gz_std'] ** 2)\n",
    "            tempdf['gyro_vector_mag'] = np.sqrt(tempdf['gx'] ** 2 + tempdf['gy'] ** 2 + tempdf['gz'] ** 2)\n",
    "            tempdf['gyro_horiz_mag'] = np.sqrt(tempdf['gx'] ** 2 + tempdf['gz'] ** 2)\n",
    "            # C2\n",
    "            tempdf['horiz_mag'] = np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2)\n",
    "            ## ======================================================================\n",
    "            \n",
    "            # 특성으로 사용하지 않을 컬럼 지우기\n",
    "            temp_list1 = tempdf['person']\n",
    "            temp_list2 = tempdf['activity']\n",
    "            \n",
    "            tempdf = tempdf.drop(['ax', 'ay', 'az', 'fx', 'fy', 'fz', 'bx', 'by', 'bz', 'gx', 'gy', 'gz', 'g_fx', 'g_fy', 'g_fz', \n",
    "                         'fx_std', 'fy_std', 'fz_std', 'bx_std', 'by_std', 'bz_std', 'gx_std', 'gy_std', 'gz_std', 'person', 'activity'], axis=1)\n",
    "            \n",
    "            tempdf.insert(loc=0,column='person',value=temp_list1)\n",
    "            tempdf.insert(loc=1,column='activity',value=temp_list2)\n",
    "            \n",
    "            df_list.append(tempdf.fillna(0))\n",
    "            \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6874ebb-ffc5-4f5f-9bac-fb3925bde6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 라벨링\n",
    "\n",
    "# 기준으로 삼을 특성, 특성들의 값이 차이가 많이나서 min_max 정규화, 어떤 특성들을 사용 할 것인지.\n",
    "def labeling(fall_list, adl_list, standard, check_list):\n",
    "    adl_df = []\n",
    "    fall_df = []\n",
    "\n",
    "    for df in fall_list:\n",
    "        df = df.loc[:,check_list]\n",
    "        k = df[standard].idxmax() # 최대값을 가지는 인덱스를 k로\n",
    "        fall = df.loc[k - 160 : k] # vm2(기준으로 잡음)가 최고점을 찍은 순간의 0.8초 전까지를 fall로 라벨렝 (미리 fall을 예측해야하므로)\n",
    "        fall['label'] = 1\n",
    "        fall_df.append(fall)\n",
    "    \n",
    "    for df in adl_list:\n",
    "        df = df.loc[120:,check_list] # ADL은 어쩌피 다 비슷하게 나올 것이므로, 데이터 크기가 커서 그냥 임의로 잘라줌\n",
    "        df['label'] = 0\n",
    "        adl_df.append(df)\n",
    "        \n",
    "    return fall_df, adl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b5acddd-c888-468f-9d6b-ba080eadd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 슬라이딩 윈도잉\n",
    "\n",
    "WINDOWSIZE = 60\n",
    "\n",
    "def windowing(fall_df, adl_df, WINDOWSIZE):\n",
    "    x = []\n",
    "    y = []\n",
    "    for df in fall_df:\n",
    "        for i in range(len(df) - WINDOWSIZE):\n",
    "            df_x = df.drop('label',axis=1).iloc[i : i+ WINDOWSIZE]\n",
    "            df_y = df['label'].iloc[1]\n",
    "            x.append(df_x)\n",
    "            y.append(df_y)\n",
    "    for df in adl_df:\n",
    "        count = 0\n",
    "        for i in range(120, len(df) - WINDOWSIZE, 20):\n",
    "            count += 1\n",
    "            df_x = df.drop('label',axis=1).iloc[i : i+ WINDOWSIZE]\n",
    "            df_y = df['label'].iloc[1]\n",
    "            x.append(df_x)\n",
    "            y.append(df_y)\n",
    "            if count > 120:\n",
    "                break\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 0)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ce03db-e57f-450e-b2ed-8f4f73906eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전처리 하는 부분\n",
    "\n",
    "# 데이터 불러오기\n",
    "fall_list, adl_list = load_dataset(person)\n",
    "\n",
    "# 데이터 특성 추출 해서 각 리스트에 담기\n",
    "fall_list = feature_extraction(fall_list)\n",
    "adl_list = feature_extraction(adl_list)\n",
    "\n",
    "# 어떤 특성을 사용할 것인지 checkList\n",
    "checkList = [\n",
    "    'vm2',\n",
    "    'g_sum',\n",
    "    'diff_sum'\n",
    "]\n",
    "\n",
    "# 데이터 라벨링\n",
    "fall_df, adl_df = labeling(fall_list, adl_list, 'vm2', checkList)\n",
    "\n",
    "# 데이터 슬라이딩 윈도잉으로 자르고, 훈련&테스트 데이터 분할\n",
    "x_train, x_test, y_train, y_test = windowing(fall_df , adl_df, 60)\n",
    "\n",
    "# 훈련데이터에서 검증데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03864dd4-16b0-4149-b50e-c8d3231ff08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 특성 시각화\n",
    "# 시각화한 특성들로 무슨 특성을 사용해야 할지 결정\n",
    "count = 0\n",
    "\n",
    "fig, ax = plt.subplots(6,5,figsize=(30,30))\n",
    "for k in range(0, 0, 10):\n",
    "    count2 = 0\n",
    "    df = fall_list[k][checkList]\n",
    "    df = (df - df.min()) / (df.max() - df.min())\n",
    "    for i in checkList:\n",
    "\n",
    "        ax[count,count2].plot(df[i], label=i)\n",
    "        ax[count,count2].plot(df['vm2'] ,label = 'vm2')\n",
    "        ax[count,count2].legend()\n",
    "        count2 += 1\n",
    "    count += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e627d-5814-4565-a604-18220c2c108c",
   "metadata": {},
   "source": [
    "### 4. 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f40239e-6c5a-421c-825e-ef68de0d6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM 모델\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128,input_shape=[WINDOWSIZE, 3], activation='tanh', return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64,  return_sequences=True,dropout=0.2 ),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5cbe9-00bc-4589-b317-b996acf7d828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021C0CD32A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021C0CD32A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.9132WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000214B0313B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000214B0313B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.17416, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 633s 66ms/step - loss: 0.2117 - accuracy: 0.9132 - val_loss: 0.1742 - val_accuracy: 0.9281\n",
      "Epoch 2/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9297\n",
      "Epoch 2: val_loss improved from 0.17416 to 0.16662, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 621s 66ms/step - loss: 0.1752 - accuracy: 0.9297 - val_loss: 0.1666 - val_accuracy: 0.9354\n",
      "Epoch 3/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9338\n",
      "Epoch 3: val_loss improved from 0.16662 to 0.15094, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.1659 - accuracy: 0.9338 - val_loss: 0.1509 - val_accuracy: 0.9416\n",
      "Epoch 4/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9370\n",
      "Epoch 4: val_loss improved from 0.15094 to 0.14844, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 620s 65ms/step - loss: 0.1567 - accuracy: 0.9370 - val_loss: 0.1484 - val_accuracy: 0.9411\n",
      "Epoch 5/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9392\n",
      "Epoch 5: val_loss did not improve from 0.14844\n",
      "9472/9472 [==============================] - 619s 65ms/step - loss: 0.1535 - accuracy: 0.9392 - val_loss: 0.1584 - val_accuracy: 0.9386\n",
      "Epoch 6/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9410\n",
      "Epoch 6: val_loss did not improve from 0.14844\n",
      "9472/9472 [==============================] - 620s 65ms/step - loss: 0.1483 - accuracy: 0.9410 - val_loss: 0.1493 - val_accuracy: 0.9419\n",
      "Epoch 7/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9434\n",
      "Epoch 7: val_loss improved from 0.14844 to 0.14397, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 616s 65ms/step - loss: 0.1431 - accuracy: 0.9434 - val_loss: 0.1440 - val_accuracy: 0.9437\n",
      "Epoch 8/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9447\n",
      "Epoch 8: val_loss did not improve from 0.14397\n",
      "9472/9472 [==============================] - 600s 63ms/step - loss: 0.1401 - accuracy: 0.9447 - val_loss: 0.1710 - val_accuracy: 0.9321\n",
      "Epoch 9/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9467\n",
      "Epoch 9: val_loss improved from 0.14397 to 0.14019, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1351 - accuracy: 0.9467 - val_loss: 0.1402 - val_accuracy: 0.9445\n",
      "Epoch 10/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9465\n",
      "Epoch 10: val_loss improved from 0.14019 to 0.12788, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1339 - accuracy: 0.9465 - val_loss: 0.1279 - val_accuracy: 0.9494\n",
      "Epoch 11/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9478\n",
      "Epoch 11: val_loss improved from 0.12788 to 0.12654, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1316 - accuracy: 0.9478 - val_loss: 0.1265 - val_accuracy: 0.9515\n",
      "Epoch 12/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9492\n",
      "Epoch 12: val_loss did not improve from 0.12654\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1287 - accuracy: 0.9492 - val_loss: 0.1331 - val_accuracy: 0.9479\n",
      "Epoch 13/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.9504\n",
      "Epoch 13: val_loss improved from 0.12654 to 0.12510, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1257 - accuracy: 0.9504 - val_loss: 0.1251 - val_accuracy: 0.9511\n",
      "Epoch 14/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9513\n",
      "Epoch 14: val_loss did not improve from 0.12510\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.1230 - accuracy: 0.9513 - val_loss: 0.1336 - val_accuracy: 0.9491\n",
      "Epoch 15/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9510\n",
      "Epoch 15: val_loss improved from 0.12510 to 0.11435, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1241 - accuracy: 0.9510 - val_loss: 0.1144 - val_accuracy: 0.9553\n",
      "Epoch 16/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9518\n",
      "Epoch 16: val_loss did not improve from 0.11435\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1216 - accuracy: 0.9518 - val_loss: 0.1231 - val_accuracy: 0.9532\n",
      "Epoch 17/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9522\n",
      "Epoch 17: val_loss did not improve from 0.11435\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.1203 - accuracy: 0.9522 - val_loss: 0.1220 - val_accuracy: 0.9517\n",
      "Epoch 18/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9530\n",
      "Epoch 18: val_loss did not improve from 0.11435\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1190 - accuracy: 0.9530 - val_loss: 0.1315 - val_accuracy: 0.9467\n",
      "Epoch 19/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9535\n",
      "Epoch 19: val_loss did not improve from 0.11435\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1177 - accuracy: 0.9535 - val_loss: 0.1161 - val_accuracy: 0.9540\n",
      "Epoch 20/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9540\n",
      "Epoch 20: val_loss improved from 0.11435 to 0.11394, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1160 - accuracy: 0.9540 - val_loss: 0.1139 - val_accuracy: 0.9562\n",
      "Epoch 21/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9549\n",
      "Epoch 21: val_loss improved from 0.11394 to 0.11008, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1140 - accuracy: 0.9549 - val_loss: 0.1101 - val_accuracy: 0.9572\n",
      "Epoch 22/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9549\n",
      "Epoch 22: val_loss did not improve from 0.11008\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1142 - accuracy: 0.9549 - val_loss: 0.1126 - val_accuracy: 0.9549\n",
      "Epoch 23/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9550\n",
      "Epoch 23: val_loss did not improve from 0.11008\n",
      "9472/9472 [==============================] - 628s 66ms/step - loss: 0.1137 - accuracy: 0.9550 - val_loss: 0.1160 - val_accuracy: 0.9558\n",
      "Epoch 24/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9548\n",
      "Epoch 24: val_loss did not improve from 0.11008\n",
      "9472/9472 [==============================] - 629s 66ms/step - loss: 0.1138 - accuracy: 0.9548 - val_loss: 0.1152 - val_accuracy: 0.9548\n",
      "Epoch 25/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9558\n",
      "Epoch 25: val_loss did not improve from 0.11008\n",
      "9472/9472 [==============================] - 628s 66ms/step - loss: 0.1121 - accuracy: 0.9558 - val_loss: 0.1423 - val_accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9558\n",
      "Epoch 26: val_loss did not improve from 0.11008\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1115 - accuracy: 0.9558 - val_loss: 0.1129 - val_accuracy: 0.9565\n",
      "Epoch 27/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9562\n",
      "Epoch 27: val_loss improved from 0.11008 to 0.10435, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 628s 66ms/step - loss: 0.1107 - accuracy: 0.9562 - val_loss: 0.1044 - val_accuracy: 0.9594\n",
      "Epoch 28/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9551\n",
      "Epoch 28: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 628s 66ms/step - loss: 0.1131 - accuracy: 0.9551 - val_loss: 0.1440 - val_accuracy: 0.9393\n",
      "Epoch 29/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9549\n",
      "Epoch 29: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1134 - accuracy: 0.9549 - val_loss: 0.1089 - val_accuracy: 0.9572\n",
      "Epoch 30/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9555\n",
      "Epoch 30: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 628s 66ms/step - loss: 0.1127 - accuracy: 0.9555 - val_loss: 0.1053 - val_accuracy: 0.9603\n",
      "Epoch 31/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9555\n",
      "Epoch 31: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1125 - accuracy: 0.9555 - val_loss: 0.1188 - val_accuracy: 0.9530\n",
      "Epoch 32/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9566\n",
      "Epoch 32: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1106 - accuracy: 0.9566 - val_loss: 0.1055 - val_accuracy: 0.9592\n",
      "Epoch 33/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9564\n",
      "Epoch 33: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1099 - accuracy: 0.9564 - val_loss: 0.1053 - val_accuracy: 0.9601\n",
      "Epoch 34/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9563\n",
      "Epoch 34: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1101 - accuracy: 0.9563 - val_loss: 0.1389 - val_accuracy: 0.9466\n",
      "Epoch 35/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9576\n",
      "Epoch 35: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1073 - accuracy: 0.9576 - val_loss: 0.1226 - val_accuracy: 0.9513\n",
      "Epoch 36/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9574\n",
      "Epoch 36: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1079 - accuracy: 0.9574 - val_loss: 0.1274 - val_accuracy: 0.9525\n",
      "Epoch 37/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9584\n",
      "Epoch 37: val_loss did not improve from 0.10435\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1067 - accuracy: 0.9584 - val_loss: 0.1218 - val_accuracy: 0.9518\n",
      "Epoch 38/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9588\n",
      "Epoch 38: val_loss improved from 0.10435 to 0.10124, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 627s 66ms/step - loss: 0.1037 - accuracy: 0.9588 - val_loss: 0.1012 - val_accuracy: 0.9610\n",
      "Epoch 39/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9592\n",
      "Epoch 39: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1030 - accuracy: 0.9592 - val_loss: 0.1069 - val_accuracy: 0.9576\n",
      "Epoch 40/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9570\n",
      "Epoch 40: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1093 - accuracy: 0.9570 - val_loss: 0.1305 - val_accuracy: 0.9450\n",
      "Epoch 41/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9582\n",
      "Epoch 41: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 626s 66ms/step - loss: 0.1063 - accuracy: 0.9582 - val_loss: 0.1191 - val_accuracy: 0.9534\n",
      "Epoch 42/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9591\n",
      "Epoch 42: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1038 - accuracy: 0.9591 - val_loss: 0.1140 - val_accuracy: 0.9553\n",
      "Epoch 43/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9597\n",
      "Epoch 43: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1024 - accuracy: 0.9597 - val_loss: 0.1026 - val_accuracy: 0.9601\n",
      "Epoch 44/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9597\n",
      "Epoch 44: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.1030 - accuracy: 0.9597 - val_loss: 0.1214 - val_accuracy: 0.9533\n",
      "Epoch 45/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9607\n",
      "Epoch 45: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.1354 - val_accuracy: 0.9449\n",
      "Epoch 46/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9602\n",
      "Epoch 46: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.1005 - accuracy: 0.9602 - val_loss: 0.1182 - val_accuracy: 0.9525\n",
      "Epoch 47/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9609\n",
      "Epoch 47: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0987 - accuracy: 0.9609 - val_loss: 0.1291 - val_accuracy: 0.9467\n",
      "Epoch 48/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9611\n",
      "Epoch 48: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0987 - accuracy: 0.9611 - val_loss: 0.1060 - val_accuracy: 0.9583\n",
      "Epoch 49/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9614\n",
      "Epoch 49: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0982 - accuracy: 0.9614 - val_loss: 0.1086 - val_accuracy: 0.9580\n",
      "Epoch 50/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9614\n",
      "Epoch 50: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0978 - accuracy: 0.9614 - val_loss: 0.1018 - val_accuracy: 0.9616\n",
      "Epoch 51/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9604\n",
      "Epoch 51: val_loss did not improve from 0.10124\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0998 - accuracy: 0.9604 - val_loss: 0.1040 - val_accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9614\n",
      "Epoch 52: val_loss improved from 0.10124 to 0.09714, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0975 - accuracy: 0.9614 - val_loss: 0.0971 - val_accuracy: 0.9625\n",
      "Epoch 53/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9618\n",
      "Epoch 53: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 621s 66ms/step - loss: 0.0971 - accuracy: 0.9618 - val_loss: 0.1152 - val_accuracy: 0.9571\n",
      "Epoch 54/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9621\n",
      "Epoch 54: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0965 - accuracy: 0.9621 - val_loss: 0.1006 - val_accuracy: 0.9610\n",
      "Epoch 55/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9618\n",
      "Epoch 55: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0974 - accuracy: 0.9618 - val_loss: 0.1223 - val_accuracy: 0.9522\n",
      "Epoch 56/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9614\n",
      "Epoch 56: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0978 - accuracy: 0.9614 - val_loss: 0.1213 - val_accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9619\n",
      "Epoch 57: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0967 - accuracy: 0.9619 - val_loss: 0.1127 - val_accuracy: 0.9565\n",
      "Epoch 58/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9626\n",
      "Epoch 58: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 622s 66ms/step - loss: 0.0952 - accuracy: 0.9626 - val_loss: 0.1192 - val_accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9621\n",
      "Epoch 59: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1119 - val_accuracy: 0.9556\n",
      "Epoch 60/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9621\n",
      "Epoch 60: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 621s 66ms/step - loss: 0.0976 - accuracy: 0.9621 - val_loss: 0.1011 - val_accuracy: 0.9607\n",
      "Epoch 61/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9610\n",
      "Epoch 61: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0990 - accuracy: 0.9610 - val_loss: 0.1107 - val_accuracy: 0.9566\n",
      "Epoch 62/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9630\n",
      "Epoch 62: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0943 - accuracy: 0.9630 - val_loss: 0.1047 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9635\n",
      "Epoch 63: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0924 - accuracy: 0.9635 - val_loss: 0.1068 - val_accuracy: 0.9583\n",
      "Epoch 64/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9632\n",
      "Epoch 64: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0933 - accuracy: 0.9632 - val_loss: 0.1119 - val_accuracy: 0.9562\n",
      "Epoch 65/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9625\n",
      "Epoch 65: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 0.1196 - val_accuracy: 0.9521\n",
      "Epoch 66/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9624\n",
      "Epoch 66: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0965 - accuracy: 0.9624 - val_loss: 0.1018 - val_accuracy: 0.9601\n",
      "Epoch 67/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9640\n",
      "Epoch 67: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.0918 - accuracy: 0.9640 - val_loss: 0.1104 - val_accuracy: 0.9553\n",
      "Epoch 68/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9632\n",
      "Epoch 68: val_loss did not improve from 0.09714\n",
      "9472/9472 [==============================] - 623s 66ms/step - loss: 0.0934 - accuracy: 0.9632 - val_loss: 0.1045 - val_accuracy: 0.9585\n",
      "Epoch 69/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9630\n",
      "Epoch 69: val_loss improved from 0.09714 to 0.09244, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0944 - accuracy: 0.9630 - val_loss: 0.0924 - val_accuracy: 0.9644\n",
      "Epoch 70/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9636\n",
      "Epoch 70: val_loss did not improve from 0.09244\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.0922 - accuracy: 0.9636 - val_loss: 0.1026 - val_accuracy: 0.9595\n",
      "Epoch 71/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9623\n",
      "Epoch 71: val_loss did not improve from 0.09244\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.0974 - accuracy: 0.9623 - val_loss: 0.1190 - val_accuracy: 0.9529\n",
      "Epoch 72/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9625\n",
      "Epoch 72: val_loss did not improve from 0.09244\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.0949 - accuracy: 0.9625 - val_loss: 0.1102 - val_accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "9469/9472 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9633\n",
      "Epoch 73: val_loss did not improve from 0.09244\n",
      "9472/9472 [==============================] - 607s 64ms/step - loss: 0.0941 - accuracy: 0.9633 - val_loss: 0.1086 - val_accuracy: 0.9584\n",
      "Epoch 74/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9640\n",
      "Epoch 74: val_loss did not improve from 0.09244\n",
      "9472/9472 [==============================] - 625s 66ms/step - loss: 0.0916 - accuracy: 0.9640 - val_loss: 0.1073 - val_accuracy: 0.9591\n",
      "Epoch 75/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9651\n",
      "Epoch 75: val_loss improved from 0.09244 to 0.09200, saving model to ./SisFall_csv\\tmp_checkpoint.h5\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0889 - accuracy: 0.9651 - val_loss: 0.0920 - val_accuracy: 0.9650\n",
      "Epoch 76/100\n",
      "9472/9472 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9634\n",
      "Epoch 76: val_loss did not improve from 0.09200\n",
      "9472/9472 [==============================] - 624s 66ms/step - loss: 0.0932 - accuracy: 0.9634 - val_loss: 0.1116 - val_accuracy: 0.9567\n",
      "Epoch 77/100\n",
      "6824/9472 [====================>.........] - ETA: 2:37 - loss: 0.0913 - accuracy: 0.9643"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics='accuracy')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "filename = os.path.join(path + 'tmp_checkpoint.h5')\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97841e98-92a2-41e4-8618-9dfa14f3f009",
   "metadata": {},
   "source": [
    "#### 모델 불러오기 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e4b05-726f-4df8-aaf0-dbe7be10e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 불러오기\n",
    "# model = keras.models.load_model('LSTM_sisfall.h5')\n",
    "\n",
    "## 모델 저장하기\n",
    "# from tensorflow.python.keras.models import load_model\n",
    "# model.save('LSTM_sisfall_v3_minmax_x.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5b2a0-ebfd-488f-bc19-cef346c07feb",
   "metadata": {},
   "source": [
    "### 5. 평가 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ab263-7a62-4088-b9c1-c8d322b16b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test)\n",
    "# print(score[1])\n",
    "# print(score[0])\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('test loss, test acc:', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisfall_py37",
   "language": "python",
   "name": "sisfall_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
